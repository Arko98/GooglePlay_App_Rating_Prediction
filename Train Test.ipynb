{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arko/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import Preprocess as util\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, Sequential, Input\n",
    "from keras.layers import Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arko/Deep Learning Works/GooglePlay_App_Rating/Preprocess.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[\"Size\"][i] = value[0]\n",
      "/home/arko/Deep Learning Works/GooglePlay_App_Rating/Preprocess.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[\"Size\"][i] = value[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data Shape = (10840, 7)\n",
      "App Rating Data Shape = (10840, 1)\n"
     ]
    }
   ],
   "source": [
    "input_data, labels = util.load_data()\n",
    "print('Input Data Shape = {}'.format(input_data.shape))\n",
    "print('App Rating Data Shape = {}'.format(labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input data shape = (8672, 7)\n",
      "Training labels shape = (8672, 1)\n",
      "Testing input data shape = (2168, 7)\n",
      "Testing labels shape = (2168, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(input_data, labels, test_size = 0.20, random_state = 42)\n",
    "print('Training input data shape = {}'.format(train_x.shape))\n",
    "print('Training labels shape = {}'.format(train_y.shape))\n",
    "print('Testing input data shape = {}'.format(test_x.shape))\n",
    "print('Testing labels shape = {}'.format(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture of Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape = (input_data.shape[1],))\n",
    "\n",
    "def model(input_value):\n",
    "    x = Dense(units = 200, activation = 'tanh')(input_value)\n",
    "    x = Dense(units = 100, activation = 'relu')(x)\n",
    "    x = Dense(units = 50, activation = 'tanh')(x)\n",
    "    x = Dense(units = 30, activation = 'relu')(x)\n",
    "    x = Dense(units = 10, activation = 'tanh')(x)\n",
    "    output = Dense(units = 1, activation = 'relu')(x)\n",
    "    model = Model(inputs = input_value, outputs = output, name = 'AppRating_model')\n",
    "    model.summary()\n",
    "    return model \n",
    "\n",
    "def compile_and_train(model, num_epochs):\n",
    "    model.compile(optimizer= 'adadelta', loss= 'mse') \n",
    "    history = model.fit(train_x, train_y, batch_size=32, epochs = num_epochs)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of Model on Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 200)               1600      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 28,601\n",
      "Trainable params: 28,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "8672/8672 [==============================] - 2s 223us/step - loss: 0.4725\n",
      "Epoch 2/200\n",
      "8672/8672 [==============================] - 1s 151us/step - loss: 0.2684\n",
      "Epoch 3/200\n",
      "8672/8672 [==============================] - 1s 139us/step - loss: 0.2635\n",
      "Epoch 4/200\n",
      "8672/8672 [==============================] - 1s 136us/step - loss: 0.2608\n",
      "Epoch 5/200\n",
      "8672/8672 [==============================] - 1s 135us/step - loss: 0.2581\n",
      "Epoch 6/200\n",
      "8672/8672 [==============================] - 1s 157us/step - loss: 0.2569\n",
      "Epoch 7/200\n",
      "8672/8672 [==============================] - 1s 157us/step - loss: 0.2558\n",
      "Epoch 8/200\n",
      "8672/8672 [==============================] - 1s 142us/step - loss: 0.2542\n",
      "Epoch 9/200\n",
      "8672/8672 [==============================] - 1s 161us/step - loss: 0.2546\n",
      "Epoch 10/200\n",
      "8672/8672 [==============================] - 1s 151us/step - loss: 0.2530\n",
      "Epoch 11/200\n",
      "8672/8672 [==============================] - 2s 173us/step - loss: 0.2531\n",
      "Epoch 12/200\n",
      "8672/8672 [==============================] - 1s 173us/step - loss: 0.2526\n",
      "Epoch 13/200\n",
      "8672/8672 [==============================] - 1s 150us/step - loss: 0.2533\n",
      "Epoch 14/200\n",
      "8672/8672 [==============================] - 1s 154us/step - loss: 0.2526\n",
      "Epoch 15/200\n",
      "8672/8672 [==============================] - 1s 150us/step - loss: 0.2516\n",
      "Epoch 16/200\n",
      "8672/8672 [==============================] - 1s 153us/step - loss: 0.2517\n",
      "Epoch 17/200\n",
      "8672/8672 [==============================] - 1s 151us/step - loss: 0.2516\n",
      "Epoch 18/200\n",
      "8672/8672 [==============================] - 1s 153us/step - loss: 0.2510\n",
      "Epoch 19/200\n",
      "8672/8672 [==============================] - 1s 163us/step - loss: 0.2522\n",
      "Epoch 20/200\n",
      "8672/8672 [==============================] - 2s 173us/step - loss: 0.2501\n",
      "Epoch 21/200\n",
      "8672/8672 [==============================] - 1s 153us/step - loss: 0.2505\n",
      "Epoch 22/200\n",
      "8672/8672 [==============================] - 1s 154us/step - loss: 0.2507\n",
      "Epoch 23/200\n",
      "8672/8672 [==============================] - 1s 164us/step - loss: 0.2501\n",
      "Epoch 24/200\n",
      "8672/8672 [==============================] - 2s 177us/step - loss: 0.2494\n",
      "Epoch 25/200\n",
      "8672/8672 [==============================] - 1s 147us/step - loss: 0.2508\n",
      "Epoch 26/200\n",
      "8672/8672 [==============================] - 1s 146us/step - loss: 0.2489\n",
      "Epoch 27/200\n",
      "8672/8672 [==============================] - 1s 122us/step - loss: 0.2488\n",
      "Epoch 28/200\n",
      "8672/8672 [==============================] - 1s 144us/step - loss: 0.2486\n",
      "Epoch 29/200\n",
      "8672/8672 [==============================] - 1s 132us/step - loss: 0.2483\n",
      "Epoch 30/200\n",
      "8672/8672 [==============================] - 1s 120us/step - loss: 0.2476\n",
      "Epoch 31/200\n",
      "8672/8672 [==============================] - 1s 125us/step - loss: 0.2475\n",
      "Epoch 32/200\n",
      "8672/8672 [==============================] - 1s 125us/step - loss: 0.2467\n",
      "Epoch 33/200\n",
      "8672/8672 [==============================] - 1s 122us/step - loss: 0.2467\n",
      "Epoch 34/200\n",
      "8672/8672 [==============================] - 1s 133us/step - loss: 0.2469\n",
      "Epoch 35/200\n",
      "8672/8672 [==============================] - 1s 126us/step - loss: 0.2468\n",
      "Epoch 36/200\n",
      "8672/8672 [==============================] - 1s 140us/step - loss: 0.2463\n",
      "Epoch 37/200\n",
      "8672/8672 [==============================] - 1s 122us/step - loss: 0.2455\n",
      "Epoch 38/200\n",
      "8672/8672 [==============================] - 1s 123us/step - loss: 0.2461\n",
      "Epoch 39/200\n",
      "8672/8672 [==============================] - 1s 119us/step - loss: 0.2453\n",
      "Epoch 40/200\n",
      "8672/8672 [==============================] - 1s 123us/step - loss: 0.2456\n",
      "Epoch 41/200\n",
      "8672/8672 [==============================] - 1s 123us/step - loss: 0.2452\n",
      "Epoch 42/200\n",
      "8672/8672 [==============================] - 1s 152us/step - loss: 0.2443\n",
      "Epoch 43/200\n",
      "8672/8672 [==============================] - 1s 145us/step - loss: 0.2450\n",
      "Epoch 44/200\n",
      "8672/8672 [==============================] - 1s 124us/step - loss: 0.2447\n",
      "Epoch 45/200\n",
      "8672/8672 [==============================] - 1s 124us/step - loss: 0.2436\n",
      "Epoch 46/200\n",
      "8672/8672 [==============================] - 1s 122us/step - loss: 0.2439\n",
      "Epoch 47/200\n",
      "8672/8672 [==============================] - 1s 121us/step - loss: 0.2431\n",
      "Epoch 48/200\n",
      "8672/8672 [==============================] - 1s 120us/step - loss: 0.2435\n",
      "Epoch 49/200\n",
      "8672/8672 [==============================] - 1s 126us/step - loss: 0.2431\n",
      "Epoch 50/200\n",
      "8672/8672 [==============================] - 1s 125us/step - loss: 0.2431\n",
      "Epoch 51/200\n",
      "8672/8672 [==============================] - 1s 119us/step - loss: 0.2433\n",
      "Epoch 52/200\n",
      "8672/8672 [==============================] - 1s 120us/step - loss: 0.2433\n",
      "Epoch 53/200\n",
      "8672/8672 [==============================] - 1s 127us/step - loss: 0.2428\n",
      "Epoch 54/200\n",
      "8672/8672 [==============================] - 1s 119us/step - loss: 0.2434\n",
      "Epoch 55/200\n",
      "8672/8672 [==============================] - 1s 123us/step - loss: 0.2430\n",
      "Epoch 56/200\n",
      "8672/8672 [==============================] - 1s 123us/step - loss: 0.2431\n",
      "Epoch 57/200\n",
      "8672/8672 [==============================] - 1s 127us/step - loss: 0.2420\n",
      "Epoch 58/200\n",
      "8672/8672 [==============================] - 1s 149us/step - loss: 0.2420\n",
      "Epoch 59/200\n",
      "8672/8672 [==============================] - 1s 138us/step - loss: 0.2424\n",
      "Epoch 60/200\n",
      "8672/8672 [==============================] - 1s 119us/step - loss: 0.2417\n",
      "Epoch 61/200\n",
      "8672/8672 [==============================] - 1s 149us/step - loss: 0.2414\n",
      "Epoch 62/200\n",
      "8672/8672 [==============================] - 1s 128us/step - loss: 0.2421\n",
      "Epoch 63/200\n",
      "8672/8672 [==============================] - 1s 127us/step - loss: 0.2411\n",
      "Epoch 64/200\n",
      "8672/8672 [==============================] - 1s 154us/step - loss: 0.2425\n",
      "Epoch 65/200\n",
      "8672/8672 [==============================] - 1s 131us/step - loss: 0.2418\n",
      "Epoch 66/200\n",
      "8672/8672 [==============================] - 1s 123us/step - loss: 0.2403\n",
      "Epoch 67/200\n",
      "8672/8672 [==============================] - 1s 146us/step - loss: 0.2407\n",
      "Epoch 68/200\n",
      "8672/8672 [==============================] - 1s 122us/step - loss: 0.2402\n",
      "Epoch 69/200\n",
      "8672/8672 [==============================] - 1s 121us/step - loss: 0.2412\n",
      "Epoch 70/200\n",
      "8672/8672 [==============================] - 1s 123us/step - loss: 0.2409\n",
      "Epoch 71/200\n",
      "8672/8672 [==============================] - 1s 124us/step - loss: 0.2402\n",
      "Epoch 72/200\n",
      "8672/8672 [==============================] - 1s 172us/step - loss: 0.2400\n",
      "Epoch 73/200\n",
      "8672/8672 [==============================] - 2s 213us/step - loss: 0.2402\n",
      "Epoch 74/200\n",
      "8672/8672 [==============================] - 1s 156us/step - loss: 0.2406\n",
      "Epoch 75/200\n",
      "8672/8672 [==============================] - 2s 177us/step - loss: 0.2399\n",
      "Epoch 76/200\n",
      "8672/8672 [==============================] - 1s 165us/step - loss: 0.2406\n",
      "Epoch 77/200\n",
      "8672/8672 [==============================] - 1s 162us/step - loss: 0.2402\n",
      "Epoch 78/200\n",
      "8672/8672 [==============================] - 1s 154us/step - loss: 0.2389\n",
      "Epoch 79/200\n",
      "8672/8672 [==============================] - 1s 160us/step - loss: 0.2405\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8672/8672 [==============================] - 1s 147us/step - loss: 0.2398\n",
      "Epoch 81/200\n",
      "8672/8672 [==============================] - 1s 142us/step - loss: 0.2394\n",
      "Epoch 82/200\n",
      "8672/8672 [==============================] - 1s 136us/step - loss: 0.2392\n",
      "Epoch 83/200\n",
      "8672/8672 [==============================] - 1s 161us/step - loss: 0.2390\n",
      "Epoch 84/200\n",
      "8672/8672 [==============================] - 1s 144us/step - loss: 0.2391\n",
      "Epoch 85/200\n",
      "8672/8672 [==============================] - 1s 158us/step - loss: 0.2397\n",
      "Epoch 86/200\n",
      "8672/8672 [==============================] - 1s 143us/step - loss: 0.2386\n",
      "Epoch 87/200\n",
      "8672/8672 [==============================] - 1s 138us/step - loss: 0.2383\n",
      "Epoch 88/200\n",
      "8672/8672 [==============================] - 1s 137us/step - loss: 0.2386\n",
      "Epoch 89/200\n",
      "8672/8672 [==============================] - 1s 146us/step - loss: 0.2399\n",
      "Epoch 90/200\n",
      "8672/8672 [==============================] - 1s 144us/step - loss: 0.2394\n",
      "Epoch 91/200\n",
      "8672/8672 [==============================] - 1s 143us/step - loss: 0.2386\n",
      "Epoch 92/200\n",
      "8672/8672 [==============================] - 1s 144us/step - loss: 0.2391\n",
      "Epoch 93/200\n",
      "8672/8672 [==============================] - 1s 145us/step - loss: 0.2386\n",
      "Epoch 94/200\n",
      "8672/8672 [==============================] - 1s 148us/step - loss: 0.2386\n",
      "Epoch 95/200\n",
      "8672/8672 [==============================] - 1s 143us/step - loss: 0.2391\n",
      "Epoch 96/200\n",
      "8672/8672 [==============================] - 1s 155us/step - loss: 0.2390\n",
      "Epoch 97/200\n",
      "8672/8672 [==============================] - 1s 155us/step - loss: 0.2376\n",
      "Epoch 98/200\n",
      "8672/8672 [==============================] - 1s 135us/step - loss: 0.2372\n",
      "Epoch 99/200\n",
      "8672/8672 [==============================] - 1s 139us/step - loss: 0.2376\n",
      "Epoch 100/200\n",
      "8672/8672 [==============================] - 1s 140us/step - loss: 0.2375\n",
      "Epoch 101/200\n",
      "8672/8672 [==============================] - 1s 147us/step - loss: 0.2371\n",
      "Epoch 102/200\n",
      "8672/8672 [==============================] - 1s 147us/step - loss: 0.2378\n",
      "Epoch 103/200\n",
      "8672/8672 [==============================] - 1s 151us/step - loss: 0.2379\n",
      "Epoch 104/200\n",
      "8672/8672 [==============================] - 2s 176us/step - loss: 0.2376\n",
      "Epoch 105/200\n",
      "8672/8672 [==============================] - 1s 137us/step - loss: 0.2383\n",
      "Epoch 106/200\n",
      "8672/8672 [==============================] - 1s 143us/step - loss: 0.2404\n",
      "Epoch 107/200\n",
      "8672/8672 [==============================] - 1s 139us/step - loss: 0.2368\n",
      "Epoch 108/200\n",
      "8672/8672 [==============================] - 1s 125us/step - loss: 0.2377\n",
      "Epoch 109/200\n",
      "8672/8672 [==============================] - 1s 135us/step - loss: 0.2367\n",
      "Epoch 110/200\n",
      "8672/8672 [==============================] - 1s 154us/step - loss: 0.2375\n",
      "Epoch 111/200\n",
      "8672/8672 [==============================] - 2s 176us/step - loss: 0.2367\n",
      "Epoch 112/200\n",
      "8672/8672 [==============================] - 1s 144us/step - loss: 0.2368\n",
      "Epoch 113/200\n",
      "8672/8672 [==============================] - 1s 163us/step - loss: 0.2378\n",
      "Epoch 114/200\n",
      "8672/8672 [==============================] - 1s 149us/step - loss: 0.2366\n",
      "Epoch 115/200\n",
      "8672/8672 [==============================] - 2s 191us/step - loss: 0.2371\n",
      "Epoch 116/200\n",
      "8672/8672 [==============================] - 2s 183us/step - loss: 0.2374\n",
      "Epoch 117/200\n",
      "8672/8672 [==============================] - 1s 140us/step - loss: 0.2355\n",
      "Epoch 118/200\n",
      "8672/8672 [==============================] - 1s 157us/step - loss: 0.2371\n",
      "Epoch 119/200\n",
      "8672/8672 [==============================] - 2s 185us/step - loss: 0.2360\n",
      "Epoch 120/200\n",
      "8672/8672 [==============================] - 1s 166us/step - loss: 0.2358\n",
      "Epoch 121/200\n",
      "8672/8672 [==============================] - 1s 142us/step - loss: 0.2364\n",
      "Epoch 122/200\n",
      "8672/8672 [==============================] - 2s 192us/step - loss: 0.2366\n",
      "Epoch 123/200\n",
      "8672/8672 [==============================] - 2s 181us/step - loss: 0.2377\n",
      "Epoch 124/200\n",
      "8672/8672 [==============================] - 1s 165us/step - loss: 0.2397\n",
      "Epoch 125/200\n",
      "8672/8672 [==============================] - 1s 133us/step - loss: 0.2384\n",
      "Epoch 126/200\n",
      "8672/8672 [==============================] - 1s 146us/step - loss: 0.2371\n",
      "Epoch 127/200\n",
      "8672/8672 [==============================] - 1s 148us/step - loss: 0.2364\n",
      "Epoch 128/200\n",
      "8672/8672 [==============================] - 1s 151us/step - loss: 0.2368\n",
      "Epoch 129/200\n",
      "8672/8672 [==============================] - 1s 153us/step - loss: 0.2368\n",
      "Epoch 130/200\n",
      "8672/8672 [==============================] - 1s 142us/step - loss: 0.2350\n",
      "Epoch 131/200\n",
      "8672/8672 [==============================] - 1s 142us/step - loss: 0.2359\n",
      "Epoch 132/200\n",
      "8672/8672 [==============================] - 1s 133us/step - loss: 0.2358\n",
      "Epoch 133/200\n",
      "8672/8672 [==============================] - 1s 146us/step - loss: 0.2363\n",
      "Epoch 134/200\n",
      "8672/8672 [==============================] - 2s 178us/step - loss: 0.2355\n",
      "Epoch 135/200\n",
      "8672/8672 [==============================] - 2s 187us/step - loss: 0.2348\n",
      "Epoch 136/200\n",
      "8672/8672 [==============================] - 2s 193us/step - loss: 0.2360\n",
      "Epoch 137/200\n",
      "8672/8672 [==============================] - 1s 171us/step - loss: 0.2352\n",
      "Epoch 138/200\n",
      "8672/8672 [==============================] - 1s 139us/step - loss: 0.2353\n",
      "Epoch 139/200\n",
      "8672/8672 [==============================] - 1s 154us/step - loss: 0.2358\n",
      "Epoch 140/200\n",
      "8672/8672 [==============================] - 1s 146us/step - loss: 0.2351\n",
      "Epoch 141/200\n",
      "8672/8672 [==============================] - 1s 145us/step - loss: 0.2357\n",
      "Epoch 142/200\n",
      "8672/8672 [==============================] - 1s 147us/step - loss: 0.2348\n",
      "Epoch 143/200\n",
      "8672/8672 [==============================] - 1s 157us/step - loss: 0.2352\n",
      "Epoch 144/200\n",
      "8672/8672 [==============================] - 1s 151us/step - loss: 0.2350\n",
      "Epoch 145/200\n",
      "8672/8672 [==============================] - 1s 145us/step - loss: 0.2339\n",
      "Epoch 146/200\n",
      "8672/8672 [==============================] - 1s 153us/step - loss: 0.2356\n",
      "Epoch 147/200\n",
      "8672/8672 [==============================] - 1s 150us/step - loss: 0.2340\n",
      "Epoch 148/200\n",
      "8672/8672 [==============================] - 1s 148us/step - loss: 0.2345\n",
      "Epoch 149/200\n",
      "8672/8672 [==============================] - 1s 145us/step - loss: 0.2350\n",
      "Epoch 150/200\n",
      "8672/8672 [==============================] - 1s 146us/step - loss: 0.2355\n",
      "Epoch 151/200\n",
      "8672/8672 [==============================] - 1s 138us/step - loss: 0.2338\n",
      "Epoch 152/200\n",
      "8672/8672 [==============================] - 1s 166us/step - loss: 0.2344\n",
      "Epoch 153/200\n",
      "8672/8672 [==============================] - 1s 163us/step - loss: 0.2336\n",
      "Epoch 154/200\n",
      "8672/8672 [==============================] - 1s 146us/step - loss: 0.2337\n",
      "Epoch 155/200\n",
      "8672/8672 [==============================] - 1s 142us/step - loss: 0.2343\n",
      "Epoch 156/200\n",
      "8672/8672 [==============================] - 1s 163us/step - loss: 0.2329\n",
      "Epoch 157/200\n",
      "8672/8672 [==============================] - 1s 150us/step - loss: 0.2345\n",
      "Epoch 158/200\n",
      "8672/8672 [==============================] - 1s 167us/step - loss: 0.2336\n",
      "Epoch 159/200\n",
      "8672/8672 [==============================] - 1s 146us/step - loss: 0.2339\n",
      "Epoch 160/200\n",
      "8672/8672 [==============================] - 1s 142us/step - loss: 0.2344\n",
      "Epoch 161/200\n",
      "8672/8672 [==============================] - 1s 158us/step - loss: 0.2347\n",
      "Epoch 162/200\n",
      "8672/8672 [==============================] - 1s 152us/step - loss: 0.2338\n",
      "Epoch 163/200\n",
      "8672/8672 [==============================] - 1s 126us/step - loss: 0.2332\n",
      "Epoch 164/200\n",
      "8672/8672 [==============================] - 1s 134us/step - loss: 0.2338\n",
      "Epoch 165/200\n",
      "8672/8672 [==============================] - 1s 129us/step - loss: 0.2328\n",
      "Epoch 166/200\n",
      "8672/8672 [==============================] - 1s 121us/step - loss: 0.2327\n",
      "Epoch 167/200\n",
      "8672/8672 [==============================] - 1s 124us/step - loss: 0.2330\n",
      "Epoch 168/200\n",
      "8672/8672 [==============================] - 2s 180us/step - loss: 0.2335\n",
      "Epoch 169/200\n",
      "8672/8672 [==============================] - 1s 150us/step - loss: 0.2354\n",
      "Epoch 170/200\n",
      "8672/8672 [==============================] - 1s 143us/step - loss: 0.2332\n",
      "Epoch 171/200\n",
      "8672/8672 [==============================] - 1s 157us/step - loss: 0.2329\n",
      "Epoch 172/200\n",
      "8672/8672 [==============================] - 1s 150us/step - loss: 0.2351\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8672/8672 [==============================] - 1s 146us/step - loss: 0.2327\n",
      "Epoch 174/200\n",
      "8672/8672 [==============================] - 1s 144us/step - loss: 0.2330\n",
      "Epoch 175/200\n",
      "8672/8672 [==============================] - 1s 135us/step - loss: 0.2324\n",
      "Epoch 176/200\n",
      "8672/8672 [==============================] - 1s 150us/step - loss: 0.2344\n",
      "Epoch 177/200\n",
      "8672/8672 [==============================] - 1s 143us/step - loss: 0.2317\n",
      "Epoch 178/200\n",
      "8672/8672 [==============================] - 1s 149us/step - loss: 0.2321\n",
      "Epoch 179/200\n",
      "8672/8672 [==============================] - 1s 152us/step - loss: 0.2320\n",
      "Epoch 180/200\n",
      "8672/8672 [==============================] - 1s 151us/step - loss: 0.2317\n",
      "Epoch 181/200\n",
      "8672/8672 [==============================] - 1s 135us/step - loss: 0.2317\n",
      "Epoch 182/200\n",
      "8672/8672 [==============================] - 1s 135us/step - loss: 0.2323\n",
      "Epoch 183/200\n",
      "8672/8672 [==============================] - 1s 161us/step - loss: 0.2336\n",
      "Epoch 184/200\n",
      "8672/8672 [==============================] - 1s 154us/step - loss: 0.2315\n",
      "Epoch 185/200\n",
      "8672/8672 [==============================] - 1s 133us/step - loss: 0.2319\n",
      "Epoch 186/200\n",
      "8672/8672 [==============================] - 1s 139us/step - loss: 0.2316\n",
      "Epoch 187/200\n",
      "8672/8672 [==============================] - 1s 140us/step - loss: 0.2325\n",
      "Epoch 188/200\n",
      "8672/8672 [==============================] - 1s 146us/step - loss: 0.2315\n",
      "Epoch 189/200\n",
      "8672/8672 [==============================] - 1s 146us/step - loss: 0.2315\n",
      "Epoch 190/200\n",
      "8672/8672 [==============================] - 1s 146us/step - loss: 0.2328\n",
      "Epoch 191/200\n",
      "8672/8672 [==============================] - 1s 148us/step - loss: 0.2321\n",
      "Epoch 192/200\n",
      "8672/8672 [==============================] - 1s 153us/step - loss: 0.2312\n",
      "Epoch 193/200\n",
      "8672/8672 [==============================] - 1s 158us/step - loss: 0.2318\n",
      "Epoch 194/200\n",
      "8672/8672 [==============================] - 1s 148us/step - loss: 0.2317\n",
      "Epoch 195/200\n",
      "8672/8672 [==============================] - 1s 152us/step - loss: 0.2316\n",
      "Epoch 196/200\n",
      "8672/8672 [==============================] - 2s 175us/step - loss: 0.2314\n",
      "Epoch 197/200\n",
      "8672/8672 [==============================] - 1s 140us/step - loss: 0.2313\n",
      "Epoch 198/200\n",
      "8672/8672 [==============================] - 1s 141us/step - loss: 0.2309\n",
      "Epoch 199/200\n",
      "8672/8672 [==============================] - 1s 140us/step - loss: 0.2317\n",
      "Epoch 200/200\n",
      "8672/8672 [==============================] - 1s 143us/step - loss: 0.2309\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "AppRating_model = model(input_tensor)\n",
    "history = compile_and_train(AppRating_model, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Training Accuracy using Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training accuracy  = 0.8818035055350554\n"
     ]
    }
   ],
   "source": [
    "def distance_accuracy(y_true,y_pred):\n",
    "    true_count = 0\n",
    "    false_count = 0\n",
    "    diff = y_true - y_pred\n",
    "    for i in range(diff.shape[0]):\n",
    "        if (diff[i] <= 0.55):\n",
    "            true_count = true_count + 1\n",
    "        else:\n",
    "            false_count = false_count + 1\n",
    "    acc = true_count/(true_count+false_count)\n",
    "    return acc\n",
    "\n",
    "y_pred = AppRating_model.predict(train_x)\n",
    "y_true = train_y\n",
    "acc = distance_accuracy(y_true,y_pred)\n",
    "print('Final Training accuracy  = {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot of Loss over Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d15d2c358>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = [i for i in range(epochs)]\n",
    "loss_list = history.history['loss']\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss and Mean Absolute Error')\n",
    "plt.plot(epoch_list,loss_list, label = 'Loss')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on Unseen Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 0s 90us/step\n",
      "Test Loss = 0.22513612043593642\n",
      "Test Accuracy = 0.8819188191881919\n"
     ]
    }
   ],
   "source": [
    "loss = AppRating_model.evaluate(test_x,test_y)\n",
    "print('Test Loss = {}'.format(loss))\n",
    "y_pred = AppRating_model.predict(test_x)\n",
    "y_true = test_y\n",
    "acc = distance_accuracy(y_true,y_pred)\n",
    "print('Test Accuracy = {}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
